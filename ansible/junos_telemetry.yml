---
- name: Collect Junos Telemetry and Export to Prometheus
  hosts: all
  connection: local
  gather_facts: no
  
  vars:
    netconf_port: 830
    # Use /output for container, ../output for host
    output_dir: "{{ '/output' if playbook_dir == '/ansible' else '../output' }}"
    raw_ml_data_dir: "{{ '/raw_ml_data' if playbook_dir == '/ansible' else '../raw_ml_data' }}"
    prometheus_pushgateway: "http://pushgateway:9091"
    rpc_config_file: "rpc_commands.yml"
    # Optional: Comma-separated list of interfaces to monitor (e.g., "et-0/0/32,et-0/0/33")
    # If not set or empty, all interfaces will be monitored
    interface_filter: ""
  
  tasks:
    - name: Ensure output directory exists
      local_action:
        module: file
        path: "{{ output_dir }}"
        state: directory
        mode: '0777'
      run_once: true
      changed_when: false
    
    - name: Clean output directory before run
      local_action:
        module: shell
        cmd: "find {{ output_dir }} -type f -delete 2>/dev/null || true"
      run_once: true
      changed_when: false
    
    - name: Load RPC commands configuration
      include_vars:
        file: "{{ rpc_config_file }}"
        name: rpc_config
    
    - name: Execute RPC commands on Junos device
      junipernetworks.junos.junos_rpc:
        rpc: "{{ item.rpc }}"
        args: "{{ item.rpc_args | default({}) }}"
        output: xml
      register: rpc_results
      loop: "{{ rpc_config.rpc_commands }}"
      loop_control:
        label: "{{ item.name }}"
    
    - name: Debug RPC output structure
      debug:
        msg: 
          - "Output type: {{ item.output | type_debug }}"
          - "Output length: {{ item.output | length if item.output is sequence else 'N/A' }}"
          - "Has output_lines: {{ 'output_lines' in item }}"
      loop: "{{ rpc_results.results }}"
      loop_control:
        label: "{{ item.item.name }}"
      when: false  # Set to true to enable debugging
    
    - name: Save raw RPC outputs
      copy:
        content: "{{ item.output | join('') if item.output is sequence else item.output }}"
        dest: "{{ output_dir }}/{{ inventory_hostname }}_{{ item.item.name }}_raw.xml"
      loop: "{{ rpc_results.results }}"
      loop_control:
        label: "{{ item.item.name }}"
    
    - name: Determine interface filter for this device
      set_fact:
        device_interface_filter: "{{ hostvars[inventory_hostname].interface_filter | default(interface_filter) }}"
    
    - name: Parse RPC outputs and convert to JSON format
      script: >
        parsers/{{ item.item.parser }}.py
        --input "{{ output_dir }}/{{ inventory_hostname }}_{{ item.item.name }}_raw.xml"
        --output "{{ output_dir }}/{{ inventory_hostname }}_{{ item.item.name }}_metrics.json"
        --device "{{ inventory_hostname }}"
        {% if device_interface_filter and (item.item.name == 'optics_diagnostics' or item.item.name == 'interface_statistics') %}--interfaces "{{ device_interface_filter }}"{% endif %}
        {% if item.item.name != 'interface_statistics' %}--format json{% endif %}
      args:
        executable: python3
        chdir: "{{ playbook_dir }}"
      environment:
        PYTHONPATH: "{{ playbook_dir }}"
      loop: "{{ rpc_results.results }}"
      loop_control:
        label: "{{ item.item.name }}"
      register: parse_results
    
    - name: Display parsing results
      debug:
        msg: "Parsed {{ item.item.item.name }}: {{ item.stdout_lines }}"
      loop: "{{ parse_results.results }}"
      loop_control:
        label: "{{ item.item.item.name }}"
      when: item.stdout_lines is defined
    
    - name: Collect PIC details for detailed transceiver information
      script: >
        scripts/collect_pic_details.py
        --host "{{ inventory_hostname }}"
        --username "{{ ansible_user }}"
        --password "{{ ansible_password }}"
        --port "{{ ansible_port | default(830) }}"
        --chassis-xml "{{ output_dir }}/{{ inventory_hostname }}_chassis_inventory_raw.xml"
        --output "{{ output_dir }}/{{ inventory_hostname }}_pic_detail_metrics.json"
        {% if hostvars[inventory_hostname].hardware_model is defined %}--platform "{{ hostvars[inventory_hostname].hardware_model }}"{% endif %}
      args:
        executable: python3
        chdir: "{{ playbook_dir }}"
      environment:
        PYTHONPATH: "{{ playbook_dir }}"
      when: "'chassis_inventory' in rpc_config.rpc_commands | map(attribute='name')"
      register: pic_detail_result
      ignore_errors: yes
    
    - name: Display PIC detail collection result
      debug:
        msg: "{{ pic_detail_result.stdout_lines }}"
      when: pic_detail_result is defined and pic_detail_result.stdout_lines is defined
    
    - name: Merge metadata into optics diagnostics
      script: >
        parsers/juniper/merge_metadata.py
        --system-info "{{ output_dir }}/{{ inventory_hostname }}_system_information_metrics.json"
        --chassis-inventory "{{ output_dir }}/{{ inventory_hostname }}_chassis_inventory_metrics.json"
        {% if pic_detail_result is defined and pic_detail_result.rc == 0 %}--pic-detail "{{ output_dir }}/{{ inventory_hostname }}_pic_detail_metrics.json"{% endif %}
        --optics-metrics "{{ output_dir }}/{{ inventory_hostname }}_optics_diagnostics_metrics.json"
        --output "{{ output_dir }}/{{ inventory_hostname }}_optics_diagnostics_metrics.json"
      args:
        executable: python3
        chdir: "{{ playbook_dir }}"
      environment:
        PYTHONPATH: "{{ playbook_dir }}"
      when: "'optics_diagnostics' in rpc_config.rpc_commands | map(attribute='name')"
      register: merge_result
      ignore_errors: yes
    
    - name: Display merge result
      debug:
        msg: "{{ merge_result.stdout_lines }}"
      when: merge_result is defined and merge_result.stdout_lines is defined
    
    - name: Write optics diagnostics to Parquet for ML training
      script: >
        scripts/write_to_parquet.py
        --input "{{ output_dir }}/{{ inventory_hostname }}_optics_diagnostics_metrics.json"
        --base-dir "{{ output_dir }}/ml_data"
        --metric-type "optical"
        --device "{{ inventory_hostname }}"
      args:
        executable: python3
        chdir: "{{ playbook_dir }}"
      environment:
        PYTHONPATH: "{{ playbook_dir }}"
      when: "'optics_diagnostics' in rpc_config.rpc_commands | map(attribute='name')"
      register: optics_parquet_result
      ignore_errors: yes
    
    - name: Write interface statistics to Parquet for ML training
      script: >
        scripts/write_to_parquet.py
        --input "{{ output_dir }}/{{ inventory_hostname }}_interface_statistics_metrics.json"
        --base-dir "{{ output_dir }}/ml_data"
        --metric-type "interface_stats"
        --device "{{ inventory_hostname }}"
      args:
        executable: python3
        chdir: "{{ playbook_dir }}"
      environment:
        PYTHONPATH: "{{ playbook_dir }}"
      when: "'interface_statistics' in rpc_config.rpc_commands | map(attribute='name')"
      register: interface_parquet_result
      ignore_errors: yes
    
    - name: Write PIC details to Parquet for ML training
      script: >
        scripts/write_to_parquet.py
        --input "{{ output_dir }}/{{ inventory_hostname }}_pic_detail_metrics.json"
        --base-dir "{{ output_dir }}/ml_data"
        --metric-type "pic_detail"
        --device "{{ inventory_hostname }}"
      args:
        executable: python3
        chdir: "{{ playbook_dir }}"
      environment:
        PYTHONPATH: "{{ playbook_dir }}"
      when: pic_detail_result is defined and pic_detail_result.rc == 0
      register: pic_parquet_result
      ignore_errors: yes
    
    - name: Push metrics to Prometheus Pushgateway
      script: >
        scripts/push_to_prometheus.py
        --pushgateway "{{ prometheus_pushgateway }}"
        --job "junos_telemetry"
        --instance "{{ inventory_hostname }}"
        --metrics-file "{{ output_dir }}/{{ inventory_hostname }}_{{ item.item.name }}_metrics.json"
        --format json
      args:
        executable: python3
      loop: "{{ rpc_results.results }}"
      loop_control:
        label: "{{ item.item.name }}"
      when: prometheus_pushgateway is defined

# Aggregate all devices into hourly Parquet files
- name: Write Hourly Parquet Files
  hosts: localhost
  connection: local
  gather_facts: no
  
  vars:
    output_dir: "{{ '../output' if playbook_dir != '/ansible' else '/output' }}"
    raw_ml_data_dir: "{{ '/raw_ml_data' if playbook_dir == '/ansible' else '../raw_ml_data' }}"
  
  tasks:
    - name: Write aggregated hourly Parquet files (interface_dom, lane_dom, interface_counters)
      script: >
        scripts/write_hourly_parquet.py
        --metrics-dir "{{ output_dir }}"
        --base-dir "{{ raw_ml_data_dir }}"
        --compression snappy
      args:
        executable: python3
        chdir: "{{ playbook_dir }}"
      environment:
        PYTHONPATH: "{{ playbook_dir }}"
      register: hourly_parquet_result
    
    - name: Display hourly Parquet results
      debug:
        msg: "{{ hourly_parquet_result.stdout_lines }}"
      when: hourly_parquet_result.stdout_lines is defined

    - name: Sync raw_ml_data to S3 datalake
      community.aws.s3_sync:
        bucket: amzn-ds-s3-rrd
        file_root: "{{ raw_ml_data_dir }}"
        key_prefix: datalake/
        region: us-east-1
      environment:
        AWS_ACCESS_KEY_ID: "{{ aws_access_key_id }}"
        AWS_SECRET_ACCESS_KEY: "{{ aws_secret_access_key }}"
        AWS_SESSION_TOKEN: "{{ aws_session_token | default('') }}"
      register: s3_sync_result
      ignore_errors: yes
      when: aws_access_key_id is defined and aws_secret_access_key is defined

    - name: Display S3 sync result
      debug:
        msg: "{{ s3_sync_result }}"
      when: s3_sync_result is defined
